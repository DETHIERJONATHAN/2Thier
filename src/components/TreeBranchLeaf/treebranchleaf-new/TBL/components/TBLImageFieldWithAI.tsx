/**
 * üñºÔ∏èüìê TBLImageFieldWithAI - Champ IMAGE avec analyse IA Gemini Vision
 * 
 * Ce composant g√®re :
 * - Upload d'image standard
 * - D√©clenchement automatique de l'analyse IA si configur√©
 * - Extraction des mesures via Gemini Vision
 * - Application des r√©sultats aux champs cibles mapp√©s
 * 
 * @module TBL/components/TBLImageFieldWithAI
 * @author 2Thier CRM Team
 */

import React, { useState, useCallback, useRef, useMemo } from 'react';
import { Upload, Button, message, Spin, Space, Tag, Tooltip, Dropdown } from 'antd';
import type { MenuProps } from 'antd';
import { 
  UploadOutlined, 
  CameraOutlined, 
  RobotOutlined, 
  LoadingOutlined,
  CheckCircleOutlined,
  ExclamationCircleOutlined,
  PictureOutlined,
  VideoCameraOutlined,
  SettingOutlined,
  ThunderboltOutlined
} from '@ant-design/icons';
import { useAuth } from '../../../../../auth/useAuth';
import { useAIMeasure, getAIMeasureConfig, type AIMeasureConfig, type AIMeasureResult } from '../../../../../hooks/useAIMeasure';
import { useSmartCameraConfig } from '../../../../../hooks/useSmartCameraConfig';
import SmartCaptureFlow from '../../../../SmartCamera/SmartCaptureFlow';
import type { CapturedPhoto } from '../../../../SmartCamera/SmartCameraMobile';
import type { MultiPhotoAnalysis } from '../../../../SmartCamera/PhotoAnalyzer';
import { ReferenceObjectsConfig } from '../../../../SmartCamera/ReferenceObjectsConfig';
import { ImageMeasurementPreview } from '../../../../ImageMeasurement/ImageMeasurementPreview';
import type { MeasurementResults, ImageAnnotations } from '../../../../../types/measurement';

interface TBLImageFieldWithAIProps {
  // Configuration du champ
  nodeId: string;
  metadata?: Record<string, unknown>;
  
  // üîß NOUVEAU: Colonnes d√©di√©es AI Measure (prioritaires sur metadata)
  aiMeasure_enabled?: boolean;
  aiMeasure_autoTrigger?: boolean;
  aiMeasure_prompt?: string;
  aiMeasure_keys?: Array<{
    id: string;
    key: string;
    label: string;
    type: string;
    targetRef?: string;
    targetLabel?: string;
  }>;
  
  imageConfig?: {
    formats?: string[];
    maxSize?: number;
    ratio?: string;
    thumbnails?: Record<string, unknown>;
  };
  
  // √âtat et handlers
  value?: string | null;
  onChange: (value: unknown) => void;
  onMeasuresExtracted?: (nodeId: string, measures: Record<string, number | string>) => void;
  
  // Props UI
  disabled?: boolean;
  size?: 'small' | 'middle' | 'large';
  style?: React.CSSProperties;
  
  // Pour appliquer les mesures aux autres champs
  onFieldUpdate?: (fieldId: string, value: unknown) => void;
}

/**
 * Composant de champ IMAGE avec support IA pour l'extraction de mesures
 */
const TBLImageFieldWithAI: React.FC<TBLImageFieldWithAIProps> = ({
  nodeId,
  metadata = {},
  // Colonnes d√©di√©es AI Measure
  aiMeasure_enabled,
  aiMeasure_autoTrigger,
  aiMeasure_prompt,
  aiMeasure_keys,
  imageConfig = {},
  value,
  onChange,
  onMeasuresExtracted,
  disabled = false,
  size = 'middle',
  style,
  onFieldUpdate
}) => {
  // Hook auth pour r√©cup√©rer l'organizationId
  const { user } = useAuth();
  const organizationId = user?.organizationId || '';
  
  // √âtat local pour l'analyse IA
  const [isAnalyzingAI, setIsAnalyzingAI] = useState(false);
  const [lastAIResult, setLastAIResult] = useState<AIMeasureResult | null>(null);
  
  // √âtats pour les modaux SmartCamera
  const [showSmartCamera, setShowSmartCamera] = useState(false);
  const [showReferenceConfig, setShowReferenceConfig] = useState(false);
  
  // üÜï √âtats pour ImageMeasurementPreview (canvas de s√©lection des lignes)
  const [showMeasurementCanvas, setShowMeasurementCanvas] = useState(false);
  const [capturedPhotos, setCapturedPhotos] = useState<CapturedPhoto[]>([]);
  const [processedImageUrl, setProcessedImageUrl] = useState<string | null>(null);
  const [processedImageBase64, setProcessedImageBase64] = useState<string | null>(null);
  const [isFromSmartCapture, setIsFromSmartCapture] = useState(false);
  // üî¨ Analyse compl√®te ArUco pour le panel Canvas
  const [arucoAnalysis, setArucoAnalysis] = useState<any>(null);
  
  // Refs pour les inputs file (galerie et cam√©ra)
  const fileInputRef = useRef<HTMLInputElement>(null);
  const cameraInputRef = useRef<HTMLInputElement>(null);
  
  // Hook pour l'analyse IA
  const { analyzeImage, applyResults } = useAIMeasure({
    onSuccess: (result) => {
      setLastAIResult(result);
      console.log('[TBLImageFieldWithAI] Analyse IA r√©ussie:', result);
    },
    onError: (error) => {
      console.error('[TBLImageFieldWithAI] Erreur analyse IA:', error);
    }
  });
  
  // Hook pour la config SmartCamera (stabilis√© pour √©viter re-renders)
  const smartCameraHook = useSmartCameraConfig(nodeId);
  const smartConfig = useMemo(() => smartCameraHook.config, [smartCameraHook.config]);
  
  // üîß NOUVEAU: R√©cup√©rer la config AI depuis les colonnes d√©di√©es OU metadata (fallback)
  const aiConfig = getAIMeasureConfig({ 
    metadata,
    // Colonnes d√©di√©es (prioritaires)
    aiMeasure_enabled,
    aiMeasure_autoTrigger,
    aiMeasure_prompt,
    aiMeasure_keys
  });
  const isAIEnabled = aiConfig?.enabled === true;
  const autoTrigger = aiConfig?.autoTrigger !== false; // true par d√©faut si AI activ√©
  
  // Debug log
  console.log('[TBLImageFieldWithAI] AI Config:', { 
    isAIEnabled, 
    autoTrigger, 
    aiMeasure_enabled,
    aiMeasure_keys,
    mappingsCount: aiConfig?.mappings?.length || 0 
  });
  
  // Configuration image
  const acceptedFormats = Array.isArray(imageConfig.formats) && imageConfig.formats.length > 0
    ? imageConfig.formats.map(fmt => (fmt.startsWith('.') ? fmt : `.${fmt.toLowerCase()}`))
    : undefined;
  const imageAccept = acceptedFormats && acceptedFormats.length > 0 ? acceptedFormats.join(',') : 'image/*';
  const maxImageSizeBytes = imageConfig.maxSize ? imageConfig.maxSize * 1024 * 1024 : undefined;
  const enforcedRatio = imageConfig.ratio;
  const imageThumbnails = imageConfig.thumbnails;

  /**
   * D√©clencher l'analyse IA sur l'image upload√©e
   */
  const triggerAIAnalysis = useCallback(async (imageBase64: string) => {
    if (!isAIEnabled || !aiConfig) {
      console.log('[TBLImageFieldWithAI] IA d√©sactiv√©e ou non configur√©e');
      return;
    }
    
    setIsAnalyzingAI(true);
    
    try {
      const result = await analyzeImage(imageBase64, aiConfig);
      
      if (result?.success && result.measures) {
        // Notifier le parent des mesures extraites
        onMeasuresExtracted?.(nodeId, result.measures);
        
        // Appliquer les r√©sultats aux champs mapp√©s
        if (onFieldUpdate && aiConfig.mappings) {
          aiConfig.mappings.forEach(mapping => {
            const measureValue = result.measures[mapping.measureKey];
            if (measureValue !== undefined && mapping.targetFieldId) {
              // Appliquer la transformation si n√©cessaire
              let finalValue: number | string = measureValue;
              if (typeof finalValue === 'number' && mapping.transform && mapping.transform !== 'none') {
                switch (mapping.transform) {
                  case 'round': finalValue = Math.round(finalValue); break;
                  case 'ceil': finalValue = Math.ceil(finalValue); break;
                  case 'floor': finalValue = Math.floor(finalValue); break;
                }
              }
              onFieldUpdate(mapping.targetFieldId, finalValue);
            }
          });
        }
        
        message.success(`üìê ${Object.keys(result.measures).length} mesure(s) extraite(s) par l'IA`);
      }
    } catch (error) {
      console.error('[TBLImageFieldWithAI] Erreur lors de l\'analyse:', error);
      message.error('Erreur lors de l\'analyse IA de l\'image');
    } finally {
      setIsAnalyzingAI(false);
    }
  }, [isAIEnabled, aiConfig, analyzeImage, onMeasuresExtracted, onFieldUpdate, nodeId]);

  /**
   * Handler de changement d'image avec d√©clenchement IA optionnel
   */
  const handleImageChange = useCallback((info: any) => {
    if (info.fileList.length > 0) {
      const file = info.fileList[0];
      if (file.originFileObj) {
        const reader = new FileReader();
        reader.onload = async (e) => {
          let imageData: any = e.target?.result;
          
          // Traiter les thumbnails si configur√©s
          if (imageThumbnails && typeof imageThumbnails === 'object') {
            imageData = {
              original: e.target?.result,
              thumbnails: imageThumbnails,
            };
          }
          
          // Mettre √† jour la valeur du champ
          onChange(imageData);
          
          // D√©clencher l'analyse IA si activ√©e et auto-trigger
          if (isAIEnabled && autoTrigger && typeof e.target?.result === 'string') {
            // Petit d√©lai pour laisser le temps √† l'UI de se mettre √† jour
            setTimeout(() => {
              triggerAIAnalysis(e.target?.result as string);
            }, 100);
          }
        };
        reader.readAsDataURL(file.originFileObj);
      }
    } else {
      onChange(null);
      setLastAIResult(null);
    }
  }, [onChange, imageThumbnails, isAIEnabled, autoTrigger, triggerAIAnalysis]);

  /**
   * Handler pour l'analyse manuelle
   */
  const handleManualAnalysis = useCallback(() => {
    if (value && typeof value === 'string') {
      triggerAIAnalysis(value);
    } else {
      message.warning('Veuillez d\'abord charger une image');
    }
  }, [value, triggerAIAnalysis]);

  /**
   * Handler pour les fichiers depuis input natif (cam√©ra ou galerie)
   */
  const handleNativeFileChange = useCallback((event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;
    
    // Validation taille
    if (maxImageSizeBytes && file.size > maxImageSizeBytes) {
      message.error(`Image trop lourde (max ${imageConfig.maxSize} Mo).`);
      return;
    }
    
    const reader = new FileReader();
    reader.onload = async (e) => {
      let imageData: any = e.target?.result;
      
      // Traiter les thumbnails si configur√©s
      if (imageThumbnails && typeof imageThumbnails === 'object') {
        imageData = {
          original: e.target?.result,
          thumbnails: imageThumbnails,
        };
      }
      
      // Mettre √† jour la valeur du champ
      onChange(imageData);
      
      // D√©clencher l'analyse IA si activ√©e et auto-trigger
      if (isAIEnabled && autoTrigger && typeof e.target?.result === 'string') {
        setTimeout(() => {
          triggerAIAnalysis(e.target?.result as string);
        }, 100);
      }
    };
    reader.readAsDataURL(file);
    
    // Reset l'input pour permettre de rechoisir le m√™me fichier
    event.target.value = '';
  }, [onChange, imageThumbnails, isAIEnabled, autoTrigger, triggerAIAnalysis, maxImageSizeBytes, imageConfig.maxSize]);

  /**
   * Ouvrir la galerie
   */
  const openGallery = useCallback(() => {
    fileInputRef.current?.click();
  }, []);

  /**
   * Ouvrir la cam√©ra directement
   */
  const openCamera = useCallback(() => {
    cameraInputRef.current?.click();
  }, []);
  
  /**
   * üî• Handler pour le SmartCamera (capture multi-photos avec ULTRA-FUSION + ArUco 105 points)
   * 
   * WORKFLOW OPTIMIS√â:
   * 1. Capturer N photos
   * 2. üöÄ OUVRIR LE CANVAS IMM√âDIATEMENT avec la premi√®re photo
   * 3. En arri√®re-plan: appeler /ultra-fusion-detect ‚Üí ArUco 105 points
   * 4. Mettre √† jour le canvas avec les coins ArUco quand l'analyse est pr√™te
   */
  const handleSmartCapture = useCallback(async (photos: CapturedPhoto[], analysis: MultiPhotoAnalysis) => {
    console.log('[TBLImageFieldWithAI] üî• SmartCamera capture:', photos.length, 'photos');
    
    if (photos.length === 0) {
      message.error('Aucune photo captur√©e');
      setShowSmartCamera(false);
      return;
    }
    
    // üöÄ OUVRIR LE CANVAS IMM√âDIATEMENT avec la premi√®re photo
    const firstPhoto = photos[0]?.imageBase64 || '';
    const base64Part = firstPhoto.includes(',') ? firstPhoto.split(',')[1] : firstPhoto;
    
    setProcessedImageUrl(firstPhoto);
    setProcessedImageBase64(base64Part);
    setIsFromSmartCapture(true);
    setCapturedPhotos(photos);
    
    // Fermer SmartCamera et ouvrir le canvas TOUT DE SUITE
    setShowSmartCamera(false);
    setShowMeasurementCanvas(true);
    
    console.log('[TBLImageFieldWithAI] üöÄ Canvas ouvert imm√©diatement!');
    
    // üî¨ Lancer l'analyse ArUco en arri√®re-plan (sans bloquer)
    message.loading({ content: 'üî¨ Analyse ArUco en cours...', key: 'ultra-fusion', duration: 0 });
    
    try {
      console.log('[TBLImageFieldWithAI] üéØ Appel /ultra-fusion-detect avec', photos.length, 'photos');
      
      const photosForFusion = photos
        .filter(p => p.imageBase64 && p.imageBase64.length > 100)
        .map(p => ({
          base64: p.imageBase64?.includes(',') ? p.imageBase64.split(',')[1] : p.imageBase64,
          mimeType: 'image/jpeg',
          metadata: p.metadata
        }));
      
      if (photosForFusion.length === 0) {
        throw new Error('Aucune photo valide');
      }
      
      const response = await fetch('/api/measurement-reference/ultra-fusion-detect', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ photos: photosForFusion }),
        credentials: 'include'
      });
      
      const result = await response.json();
      
      if (!result.success) {
        throw new Error(result.error || 'Fusion √©chou√©e');
      }
      
      console.log('[TBLImageFieldWithAI] ‚úÖ Analyse ArUco termin√©e!');
      console.log(`   üèÜ Meilleure photo: ${result.bestPhoto?.index} (score: ${(result.bestPhoto?.score * 100).toFixed(1)}%)`);
      console.log(`   üìä D√©tections: ${result.metrics?.successfulDetections}/${result.metrics?.inputPhotos}`);
      
      if (result.ultraPrecision) {
        console.log(`   üî¨ Ultra-pr√©cision: ${result.ultraPrecision.totalPoints} points`);
        console.log(`      ‚úÖ Pr√©cision: ${result.ultraPrecision.estimatedPrecision}`);
        
        // üî¨ Stocker l'analyse compl√®te ArUco pour le panel Canvas
        if (result.arucoAnalysis) {
          console.log(`   üìä Analyse ArUco: rotX=${result.arucoAnalysis.pose?.rotX}¬∞, depth=${result.arucoAnalysis.depth?.estimatedCm}cm`);
          setArucoAnalysis(result.arucoAnalysis);
        }
        
        message.success({ 
          content: `üéØ ArUco d√©tect√©! Photo ${result.bestPhoto?.index + 1} (${result.ultraPrecision.estimatedPrecision})`, 
          key: 'ultra-fusion' 
        });
        
        // üèÜ Mettre √† jour avec la MEILLEURE photo si diff√©rente
        const bestPhotoIndex = result.bestPhoto?.index || 0;
        if (bestPhotoIndex > 0 && result.bestPhotoBase64) {
          const bestImage = `data:image/jpeg;base64,${result.bestPhotoBase64}`;
          setProcessedImageUrl(bestImage);
          setProcessedImageBase64(result.bestPhotoBase64);
          console.log(`[TBLImageFieldWithAI] üîÑ Mise √† jour avec la meilleure photo (index ${bestPhotoIndex})`);
        }
        
        // üéØ Stocker les coins ArUco pour le canvas (il va les d√©tecter via fusedCorners)
        if (result.fusedCorners) {
          // üîß Extraire la correction optimale calcul√©e par l'API
          const optimalCorrection = result.optimalCorrection || null;
          if (optimalCorrection) {
            console.log(`   üéØ Correction optimale: √ó${optimalCorrection.finalCorrection?.toFixed(4)} (confiance: ${(optimalCorrection.globalConfidence * 100).toFixed(0)}%)`);
          }
          
          const enrichedPhotos = photos.map((photo, idx) => ({
            imageBase64: idx === bestPhotoIndex && result.bestPhotoBase64 
              ? result.bestPhotoBase64 
              : photo.imageBase64?.includes(',') ? photo.imageBase64.split(',')[1] : photo.imageBase64 || '',
            mimeType: 'image/jpeg',
            metadata: {
              ...photo.metadata,
              qualityScore: result.allPhotoScores?.find((d: any) => d.index === idx)?.score || 85,
              sharpness: 85,
              arucoDetected: idx === bestPhotoIndex,
              ultraPrecision: idx === bestPhotoIndex ? result.ultraPrecision : null,
              // üéØ PASSER LES COINS ARUCO AU CANVAS
              fusedCorners: idx === bestPhotoIndex ? result.fusedCorners : null,
              // üîß CORRECTION OPTIMALE pour appliquer aux mesures
              optimalCorrection: idx === bestPhotoIndex ? optimalCorrection : null,
              homography: null
            }
          }));
          setCapturedPhotos(enrichedPhotos as any);
        }
      } else {
        console.log('   ‚ö†Ô∏è ArUco non d√©tect√©');
        message.warning({ 
          content: '‚ö†Ô∏è ArUco non d√©tect√©, calibration manuelle n√©cessaire', 
          key: 'ultra-fusion' 
        });
      }
      
    } catch (error: any) {
      console.error('[TBLImageFieldWithAI] ‚ùå Erreur analyse ArUco:', error);
      message.warning({ content: `Calibration manuelle requise: ${error.message}`, key: 'ultra-fusion' });
      // Le canvas est d√©j√† ouvert, l'utilisateur peut calibrer manuellement
    }
  }, []);

  /**
   * üÜï Handler pour la validation des mesures depuis ImageMeasurementCanvas
   */
  const handleMeasurementsComplete = useCallback((measurements: MeasurementResults, annotations?: ImageAnnotations) => {
    console.log('[TBLImageFieldWithAI] Mesures extraites:', measurements, 'annotations:', annotations);
    
    // Sauvegarder l'image trait√©e dans le champ
    if (processedImageUrl) {
      onChange(processedImageUrl);
    }
    
    // Appliquer les mesures aux champs mapp√©s
    if (aiMeasure_keys && onFieldUpdate) {
      let appliedCount = 0;
      aiMeasure_keys.forEach(mapping => {
        // Acc√©der √† la mesure par cl√© (string index)
        const value = measurements[mapping.key as keyof MeasurementResults];
        if (value !== undefined && mapping.targetRef) {
          console.log(`[TBLImageFieldWithAI] Application: ${mapping.key} = ${value} ‚Üí ${mapping.targetRef}`);
          onFieldUpdate(mapping.targetRef, value);
          appliedCount++;
        }
      });
      
      if (appliedCount > 0) {
        message.success(`üìê ${appliedCount} mesure(s) appliqu√©e(s) aux champs !`);
      }
    }
    
    // Fermer le canvas
    setShowMeasurementCanvas(false);
  }, [processedImageUrl, onChange, aiMeasure_keys, onFieldUpdate]);

  /**
   * üÜï Handler pour l'annulation du canvas de mesure
   */
  const handleMeasurementCancel = useCallback(() => {
    console.log('[TBLImageFieldWithAI] Canvas de mesure annul√©');
    setShowMeasurementCanvas(false);
    // Optionnel: r√©ouvrir SmartCamera si l'utilisateur veut reprendre des photos
  }, []);

  /**
   * Menu dropdown pour choisir entre galerie et cam√©ra
   */
  const uploadMenuItems: MenuProps['items'] = [
    {
      key: 'gallery',
      icon: <PictureOutlined />,
      label: 'Galerie photos',
      onClick: openGallery
    },
    {
      key: 'camera',
      icon: <VideoCameraOutlined />,
      label: 'Prendre une photo',
      onClick: openCamera
    }
  ];

  return (
    <div className="tbl-image-field-with-ai">
      <Space direction="vertical" style={{ width: '100%' }}>
        {/* Inputs file cach√©s */}
        <input
          ref={fileInputRef}
          type="file"
          accept={imageAccept}
          onChange={handleNativeFileChange}
          style={{ display: 'none' }}
        />
        <input
          ref={cameraInputRef}
          type="file"
          accept="image/*"
          capture="environment"
          onChange={handleNativeFileChange}
          style={{ display: 'none' }}
        />
        
        {/* Boutons d'action - Simplifi√©s: uniquement multi-photo et mesure */}
        <Space wrap>
          {/* üéØ SmartCamera IA (multi-photos) - Bouton principal */}
          {aiMeasure_enabled && (
            <>
              <Tooltip title="üì∏ Multi-photos + Mesures ArUco">
                <Button
                  icon={<ThunderboltOutlined />}
                  onClick={() => setShowSmartCamera(true)}
                  disabled={disabled || isAnalyzingAI}
                  size={size}
                  type="primary"
                  style={{ background: '#722ed1', borderColor: '#722ed1' }}
                >
                  Multi-Photo
                </Button>
              </Tooltip>
              
              {/* üÜï Bouton pour rouvrir le canvas de mesure sur l'image existante */}
              {value && (
                <Tooltip title="üìê Mesurer l'image actuelle">
                  <Button
                    icon={<RobotOutlined />}
                    onClick={() => {
                      setProcessedImageUrl(typeof value === 'string' ? value : (value as any)?.original);
                      setProcessedImageBase64(
                        typeof value === 'string' 
                          ? value.split(',')[1] || value 
                          : (value as any)?.original?.split(',')[1] || (value as any)?.original
                      );
                      setShowMeasurementCanvas(true);
                    }}
                    disabled={disabled || isAnalyzingAI}
                    size={size}
                    type="default"
                    style={{ borderColor: '#1890ff', color: '#1890ff' }}
                  >
                    Mesurer
                  </Button>
                </Tooltip>
              )}
            </>
          )}
        </Space>
        
        {/* Aper√ßu de l'image */}
        {value && (
          <div style={{ position: 'relative', display: 'inline-block' }}>
            <img 
              src={typeof value === 'string' ? value : (value as any)?.original}
              alt="preview" 
              style={{ 
                width: '150px', 
                height: '150px', 
                objectFit: 'cover', 
                border: '1px solid #d9d9d9',
                borderRadius: '6px',
                opacity: isAnalyzingAI ? 0.5 : 1
              }} 
            />
            
            {/* Indicateur d'analyse en cours */}
            {isAnalyzingAI && (
              <div style={{
                position: 'absolute',
                top: 0,
                left: 0,
                right: 0,
                bottom: 0,
                display: 'flex',
                alignItems: 'center',
                justifyContent: 'center',
                background: 'rgba(255,255,255,0.7)',
                borderRadius: '6px'
              }}>
                <Spin indicator={<LoadingOutlined style={{ fontSize: 24 }} spin />} tip="Analyse IA..." />
              </div>
            )}
          </div>
        )}
        
        {/* Bouton d'analyse manuelle si pas auto-trigger */}
        {isAIEnabled && !autoTrigger && value && !isAnalyzingAI && (
          <Button 
            type="primary"
            ghost
            icon={<RobotOutlined />}
            onClick={handleManualAnalysis}
            size="small"
          >
            Analyser avec IA
          </Button>
        )}
        
        {/* R√©sultat de la derni√®re analyse */}
        {lastAIResult && (
          <div style={{ 
            marginTop: 8, 
            padding: '8px 12px', 
            background: lastAIResult.success ? '#f6ffed' : '#fff2f0',
            border: `1px solid ${lastAIResult.success ? '#b7eb8f' : '#ffccc7'}`,
            borderRadius: '6px',
            fontSize: '12px'
          }}>
            {lastAIResult.success ? (
              <Space direction="vertical" size={4} style={{ width: '100%' }}>
                <div style={{ color: '#52c41a' }}>
                  <CheckCircleOutlined /> Mesures extraites :
                </div>
                {Object.entries(lastAIResult.measures).map(([key, val]) => (
                  <div key={key} style={{ paddingLeft: 16 }}>
                    <strong>{key}:</strong> {val}
                  </div>
                ))}
              </Space>
            ) : (
              <div style={{ color: '#ff4d4f' }}>
                <ExclamationCircleOutlined /> {lastAIResult.error || 'Erreur lors de l\'analyse'}
              </div>
            )}
          </div>
        )}
      </Space>
      
      {/* üéØ NOUVEAU: Modaux SmartCamera - Visibles si capacit√© aiMeasure activ√©e */}
      {aiMeasure_enabled && (
        <>
          {/* Modal de capture SmartCamera multi-photos */}
          <SmartCaptureFlow
            visible={showSmartCamera}
            onClose={() => setShowSmartCamera(false)}
            onComplete={handleSmartCapture}
            targetObject="custom"
            objectLabel="panneau solaire"
          />
          
          {/* Modal de configuration des objets de r√©f√©rence */}
          <ReferenceObjectsConfig
            visible={showReferenceConfig}
            onClose={() => setShowReferenceConfig(false)}
            nodeId={nodeId}
          />
          
          {/* üÜï Modal de mesure interactive (canvas avec s√©lection de lignes) */}
          <ImageMeasurementPreview
            visible={showMeasurementCanvas && !!processedImageUrl}
            imageUrl={processedImageUrl || ''}
            imageBase64={processedImageBase64 || undefined}
            organizationId={organizationId}
            nodeId={nodeId}
            onComplete={handleMeasurementsComplete}
            onCancel={handleMeasurementCancel}
            measureKeys={aiMeasure_keys?.map(k => k.key) || ['largeur_cm', 'hauteur_cm']}
            allPhotos={capturedPhotos.map(photo => ({
              imageBase64: photo.imageBase64?.includes(',') 
                ? photo.imageBase64.split(',')[1] 
                : photo.imageBase64 || '',
              mimeType: 'image/jpeg',
              metadata: {
                qualityScore: (photo.metadata as any)?.qualityScore || photo.metadata?.quality?.overallScore || 85,
                sharpness: (photo.metadata as any)?.sharpness || photo.metadata?.quality?.sharpness || 85,
                brightness: photo.metadata?.lighting?.brightness || 128,
                // üéØ ULTRA-PRECISION: Passer les donn√©es ArUco d√©tect√©es !
                arucoDetected: (photo.metadata as any)?.arucoDetected,
                ultraPrecision: (photo.metadata as any)?.ultraPrecision,
                homography: (photo.metadata as any)?.homography,
                // üîß CORRECTION OPTIMALE - CRITIQUE: Passer pour application aux mesures !
                optimalCorrection: (photo.metadata as any)?.optimalCorrection,
                // üéØ NOUVEAU: Passer aussi fusedCorners dans les metadata
                fusedCorners: (photo.metadata as any)?.fusedCorners
              }
            }))}
            // üéØ ULTRA-PRECISION: Passer les corners fusionn√©s si disponibles
            fusedCorners={(() => {
              const bestPhoto = capturedPhotos.find(p => (p.metadata as any)?.arucoDetected);
              const ultraPrecision = (bestPhoto?.metadata as any)?.ultraPrecision;
              if (ultraPrecision?.corners) {
                // Les corners sont d√©j√† en % depuis l'API
                return {
                  topLeft: ultraPrecision.corners.topLeft,
                  topRight: ultraPrecision.corners.topRight,
                  bottomRight: ultraPrecision.corners.bottomRight,
                  bottomLeft: ultraPrecision.corners.bottomLeft
                };
              }
              return undefined;
            })()}
            // üéØ Indiquer que l'homographie est pr√™te si ArUco d√©tect√©
            homographyReady={capturedPhotos.some(p => (p.metadata as any)?.arucoDetected)}
            // üî¨ Analyse compl√®te ArUco pour le panel d'infos d√©taill√©
            arucoAnalysis={arucoAnalysis}
          />
        </>
      )}
    </div>
  );
};

export default TBLImageFieldWithAI;
